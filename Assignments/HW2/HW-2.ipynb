{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "473cf89b",
      "metadata": {
        "id": "473cf89b"
      },
      "source": [
        "# Homework 2: Randomized Block and Latin Square Designs\n",
        "## Dr. Austin R. Brown\n",
        "### School of Data Science & Analytics\n",
        "### Kennesaw State University\n",
        "\n",
        "**DUE: October 3, 2025**\n",
        "\n",
        "**PART 1 INSTRUCTIONS:** You are an educational researcher interested in comparing different methods for teaching data science to undergraduate students. There are three different methods you are interested in comparing: (1) Direct Instruction (traditional method); (2) Inquiry-Based Learning (teacher facilitates student problem solving); (3) Collaborative Learning (students working in small groups). To compare these methods, you decide to randomly recruit undergraduate data science students to be part of a workshop on hypothesis testing basics. Students will be randomly assigned to one of three workshops, where each workshop employs a different teaching method. At the end of the workshop, students will be given a 50-question quiz where their understanding of hypothesis testing will be assessed. Percentage scores on this quiz serve as the outcome of interest.\n",
        "\n",
        "However, it would be apparent that the prior level of knowledge a student possess about hypothesis testing may serve as a potential confounding variable that you would want to control for. Thus, the Prior Knowledge a given student has about hypothesis testing is categorized into \"High\" and \"Low\". The data from this experiment are contained in the `Data Science Teaching Method.xlsx` file. With these data, your tasks are:\n",
        "\n",
        "**Question 1.** Briefly define the objective of this experiment\n",
        "\n",
        "A. The primary objective is to rigorously compare the effectiveness of three distinct methods for teaching data science to undergraduate students. By evaluating each method’s impact on student outcomes, the experiment aims to identify which teaching strategy leads to the highest level of student learning. Importantly, the study controls for prior knowledge in hypothesis testing—a factor that might otherwise confound results—by using it as a blocking variable. This ensures that the observed differences in student performance are due to the teaching method itself rather than variations in students’ prior preparation.\n",
        "\n",
        "**Question 2.** Specify the outcome variable\n",
        "\n",
        "A. The outcome variable is the students’ measured performance after the instructional period. Typically, this is operationalized as the score on a standardized post-instruction assessment designed to evaluate mastery of relevant data science concepts. This quantitative measure allows for objective comparison across the three teaching methods.\n",
        "\n",
        "**Question 3.** Specify the independent variable and blocking factor. What are some possible lurking variables?\n",
        "\n",
        "- **Independent Variable:** The teaching method (Method 1, Method 2, Method 3). This is the main variable being manipulated to observe its effect on student outcomes.\n",
        "- **Blocking Factor:** Students’ prior knowledge of hypothesis testing (categorized as low, medium, or high). By blocking on this variable, we control for its influence and isolate the effect of the teaching method.\n",
        "- **Possible Lurking Variables:** Factors such as instructor effectiveness, classroom environment, time of day, student motivation, and background in mathematics or statistics could influence outcomes but are not directly controlled in this study.\n",
        "\n",
        "**Question 4.** Briefly explain why a randomized block design would be appropriate here. Similarly, explain why a completely randomized design would not be appropriate.\n",
        "\n",
        "A. A randomized block design is suitable because it accounts for the variability introduced by differences in prior knowledge among students. Blocking ensures that each teaching method is evaluated across similar groups, reducing unexplained variance and increasing statistical power. In contrast, a completely randomized design would ignore prior knowledge, potentially conflating its effects with those of the teaching methods and leading to biased conclusions.\n",
        "\n",
        "**Question 5.** State the null and alternative hypotheses for this experiment.\n",
        "\n",
        "- **Null Hypothesis (H₀):** The mean performance scores of students are the same across all teaching methods; there is no effect of teaching method.\n",
        "- **Alternative Hypothesis (H₁):** At least one teaching method leads to a different mean performance score, indicating a significant effect of teaching method on student outcomes.\n",
        "\n",
        "**Question 6.** Perform appropriate exploratory analysis, including summary statistics **and** data visualizations. Do the results of these analyses support the null or alternative hypothesis more strongly?\n",
        "\n",
        "**Question 7.** Build a two-way ANOVA model. Test the assumption of normality using **both** a visual method and a testing method. Do the results of the normality test(s) support the assumption of normality?\n",
        "\n",
        "**Question 8.** Test the assumption of homogeneity of variance using **both** a visual method and a testing method. Do the results of the test(s) support the assumption of homogeneity of variance?\n",
        "\n",
        "**Question 9.** Report the F-statistic and its associated p-value for the treatment effect. Which of our two hypotheses is more strongly supported? Why?\n",
        "\n",
        "**Question 10.** If the data more strongly support the alternative hypothesis, perform Tukey's HSD post-hoc test to determine which levels of the treatment effect are significantly different from each other. If the data more strongly support the null hypothesis, explain why a post-hoc test would not be appropriate.\n",
        "\n",
        "**Question 11.** Write a brief, contextual conclusion summarizing the results of your analyses, including potential limitations of this experiment.\n",
        "\n",
        "**PART 2 INSTRUCTIONS**: Now suppose a university is evaluating the effectiveness of four different online learning platforms (say A, B, C, and D) on student engagement for students taking an undergraduate data science course in an online synchronous format. One section of the course is offered Monday through Thursday in the Morning, Early Afternoon, Mid-Afternoon, and Evening sections. Student engagement is measured through the total number of logins to the online learning platform for a given course section over the course of the\n",
        "semester. Below is a table describing the study design and factors:\n",
        "\n",
        "\n",
        "| Section \\ Day     | Monday | Tuesday | Wednesday | Thursday |\n",
        "|-------------------|--------|---------|-----------|----------|\n",
        "| **Morning**       | A      | B       | C         | D        |\n",
        "| **Early Afternoon** | B      | C       | D         | A        |\n",
        "| **Mid-Afternoon** | C      | D       | A         | B        |\n",
        "| **Evening**       | D      | A       | B         | C        |\n",
        "\n",
        "\n",
        "Here, our main interest is in comparing engagement across the online learning platforms, but we also want to control for Day of the Week as well as Time of Day, as these could potentially be confounding variables. The data for this experiment are contained in the `Online Learning and Engagement.xlsx` file. With these data, your tasks are:\n",
        "\n",
        "**Question 1.** Briefly define the objective of this experiment\n",
        "\n",
        "**Question 2.** Specify the outcome variable\n",
        "\n",
        "**Question 3.** Specify the independent variable and blocking factors. What are some other possible lurking variables?\n",
        "\n",
        "**Question 4.** Briefly explain why a Latin Square Design would be appropriate here. Similarly, explain why a completely randomized design or randomized block design would not be appropriate.\n",
        "\n",
        "**Question 5.** State the null and alternative hypotheses for this experiment.\n",
        "\n",
        "**Question 6.** Perform appropriate exploratory analysis, including summary statistics **and** data visualizations. Do the results of these analyses support the null or alternative hypothesis more strongly?\n",
        "\n",
        "**Question 7.** Build a three-way ANOVA model. Test the assumption of normality using **both** a visual method and a testing method. Do the results of the normality test(s) support the assumption of normality?\n",
        "\n",
        "**Question 8.** Test the assumption of homogeneity of variance using **both** a visual method and a testing method. Do the results of the test(s) support the assumption of homogeneity of variance?\n",
        "\n",
        "**Question 9.** Report the F-statistic and its associated p-value for the treatment effect. Which of our two hypotheses is more strongly supported? Why?\n",
        "\n",
        "**Question 10.** If the data more strongly support the alternative hypothesis, perform Tukey's HSD post-hoc test to determine which levels of the treatment effect are significantly different from each other. If the data more strongly support the null hypothesis, explain why a post-hoc test would not be appropriate.\n",
        "\n",
        "**Question 11.** Write a brief conclusion summarizing the results of your analyses, including potential limitations of this experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6.** Perform appropriate exploratory analysis, including summary statistics **and** data visualizations. Do the results of these analyses support the null or alternative hypothesis more strongly?"
      ],
      "metadata": {
        "id": "wFTowMlBlAF2"
      },
      "id": "wFTowMlBlAF2"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Use the raw GitHub URL for the Excel file\n",
        "df = pd.read_excel(\"https://github.com/LalithAditya0802/STAT-7220-Applied-Experimental-Design/raw/main/Assignments/HW2/Data%20Science%20Teaching%20Method.xlsx\")\n",
        "print(df.groupby(['Method', 'Prior_Knowledge'])['Score'].describe())\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.boxplot(x='Method', y='Score', hue='Prior_Knowledge', data=df)\n",
        "plt.title('Scores by Teaching Method and Prior Knowledge')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "tJtMOWSXlBmF",
        "outputId": "d15ed984-89bb-4b95-a665-e3f9f6994737"
      },
      "id": "tJtMOWSXlBmF",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Excel file format cannot be determined, you must specify an engine manually.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-700558162.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://github.com/LalithAditya0802/STAT-7220-Applied-Experimental-Design/blob/main/Assignments/HW2/Data%20Science%20Teaching%20Method.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Method'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Prior_Knowledge'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n\u001b[1;32m   1553\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   1555\u001b[0m                         \u001b[0;34m\"Excel file format cannot be determined, you must specify \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m                         \u001b[0;34m\"an engine manually.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Excel file format cannot be determined, you must specify an engine manually."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}